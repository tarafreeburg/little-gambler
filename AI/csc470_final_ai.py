# -*- coding: utf-8 -*-
"""CSC470_Final_AI.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r5eZtpGPMD7lTd14gI1yNYqnt_sUfYNa
"""

#Imports hell

import numpy as np
import pandas as pd
from math import sqrt

from sklearn.preprocessing import StandardScaler

from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.linear_model import LogisticRegression

from sklearn.model_selection import GridSearchCV #to find good parameters

from sklearn.preprocessing import LabelEncoder
from sklearn.preprocessing import OneHotEncoder

import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split

#metric measurement
from sklearn import metrics

#setting up the encoders, scalers, and whatever else

encoder = OneHotEncoder(sparse_output = False)
scaler = StandardScaler()
label_encoder = LabelEncoder()

pd.set_option('display.max_columns', None) #setting up display so I can see stuff easier

#reading in file. by itself due to importantce
games = pd.read_csv('matches.csv')

#things to drop: Unamed: 0, Comp, Notes, Season, Attendance, Match Report
games = games.drop(['Unnamed: 0', 'Comp', 'Notes', 'Season', 'Attendance', 'Match Report'], axis = 1)
#keurbel said we can drop the following
games = games.drop(['Captain', 'Formation', 'Dist'], axis = 1)

print(games.columns)
print(games.head(35))

#seeing plot of missing data
plt.figure(figsize=(10,7))
sns.heatmap(games.isnull(),cmap="viridis",cbar=False,yticklabels=False)

#placing 'Opponent_' before the opponent team name so we don't get models of the same
games['Opponent'] = 'Opponent_' + games['Opponent']

#Encoding ~~hell~~ Fun

Team_encoded = encoder.fit_transform(games[['Team']])
Team_encoded_df = pd.DataFrame(Team_encoded, columns=encoder.categories_[0])
games = pd.concat([games.drop('Team', axis = 1), Team_encoded_df], axis=1)

Referee_encoded = encoder.fit_transform(games[['Referee']])
Referee_encoded_df = pd.DataFrame(Referee_encoded, columns=encoder.categories_[0])
games = pd.concat([games.drop('Referee', axis = 1), Referee_encoded_df], axis=1)

Opponent_encoded = encoder.fit_transform(games[['Opponent']])
Opponent_encoded_df = pd.DataFrame(Opponent_encoded, columns=encoder.categories_[0])
games = pd.concat([games.drop('Opponent', axis = 1), Opponent_encoded_df], axis=1)

#having our y be one-hot encoded is a mess, simple encoding is fineeeeeee
#Result_encoded = encoder.fit_transform(games[['Result']])
#Result_encoded_df = pd.DataFrame(Result_encoded, columns=encoder.categories_[0])
#games = pd.concat([games.drop('Result', axis = 1), Result_encoded_df], axis = 1)


#simple encoding
games['Venue'] = label_encoder.fit_transform(games['Venue'])
games['Day'] = label_encoder.fit_transform(games['Day'])
games['Result'] = label_encoder.fit_transform(games['Result'])

#removing the word 'matchweek X' to only include the number X

games['Round'] = games['Round'].str.replace('Matchweek ', '', regex=False)

# Convert the result to an integer (optional)
games['Round'] = games['Round'].astype(int)

#making 'date' to unix time
games["DateTime"] = pd.to_datetime(games["Date"] + " " + games["Time"])
games["Unix_Time"] = games["DateTime"].astype('int64') // 10**9

games = games.drop(['Date', 'Time', 'DateTime'], axis = 1)
print(games.columns)
print(games.head(35))

#seeing plot after onehot
plt.figure(figsize=(10,7))
sns.heatmap(games.isnull(),cmap="viridis",cbar=False,yticklabels=False)

print(games.columns)

#creating the dataframes
X = games[['Round', 'Day', 'Venue', 'GF', 'GA', 'xG', 'xGA', 'Poss', 'Sh', 'SoT',
       'FK', 'PK', 'PKatt', 'Arsenal', 'AstonVilla', 'Bournemouth',
       'Brentford', 'BrightonandHoveAlbion', 'Burnley', 'Chelsea',
       'CrystalPalace', 'Everton', 'Fulham', 'Liverpool', 'LutonTown',
       'ManchesterCity', 'ManchesterUnited', 'NewcastleUnited',
       'NottinghamForest', 'SheffieldUnited', 'TottenhamHotspur',
       'WestHamUnited', 'WolverhamptonWanderers', 'Andy Madley',
       'Anthony Taylor', 'Chris Kavanagh', 'Craig Pawson', 'Darren Bond',
       'Darren England', 'David Coote', 'Graham Scott', 'Jarred Gillett',
       'John Brooks', 'Joshua Smith', 'Lewis Smith', 'Matt Donohue',
       'Michael Oliver', 'Michael Salisbury', 'Paul Tierney', 'Peter Bankes',
       'Rebecca Welch', 'Robert Jones', 'Robert Madley', 'Samuel Allison',
       'Samuel Barrott', 'Simon Hooper', 'Stuart Attwell', 'Sunny Singh',
       'Thomas Bramall', 'Tim Robinson', 'Tony Harrington', 'Opponent_Arsenal',
       'Opponent_Aston Villa', 'Opponent_Bournemouth', 'Opponent_Brentford',
       'Opponent_Brighton', 'Opponent_Burnley', 'Opponent_Chelsea',
       'Opponent_Crystal Palace', 'Opponent_Everton', 'Opponent_Fulham',
       'Opponent_Liverpool', 'Opponent_Luton Town', 'Opponent_Manchester City',
       'Opponent_Manchester Utd', 'Opponent_Newcastle Utd',
       'Opponent_Nott\'ham Forest', 'Opponent_Sheffield Utd',
       'Opponent_Tottenham', 'Opponent_West Ham', 'Opponent_Wolves','Unix_Time']]

y = games['Result']

#before fitting, let's split up the data between training and testing. Would do validation but I can't be asked.
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25) #random state used for testing

#let's fit a basic KNN
base_KNN = KNeighborsClassifier(n_neighbors=3)
base_KNN.fit(X_train, np.ravel(y_train))
basic_knn_y_pred = base_KNN.predict(X_test)

basic_knn_score = base_KNN.score(X_test, y_test)
print('Accuracy score is ', end="")
print('%.3f' % basic_knn_score)

print("")
print("KNN model precision:", metrics.precision_score(np.ravel(y_test), basic_knn_y_pred, average = 'macro'))
print("KNN model recall:", metrics.recall_score(np.ravel(y_test), basic_knn_y_pred, average = 'macro'))
print("KNN model kappa:", metrics.cohen_kappa_score(np.ravel(y_test), basic_knn_y_pred))


basic_knn_confMatrix = metrics.confusion_matrix(np.ravel(y_test), basic_knn_y_pred)
print("\nConfusion matrix:\n", basic_knn_confMatrix)

#basic LDA
basic_LDAmodel = LinearDiscriminantAnalysis()
basic_LDAmodel.fit(X_train, np.ravel(y_train))
basic_LDAModel_pred = basic_LDAmodel.predict(X_test)

basic_LDA_score = basic_LDAmodel.score(X_test, np.ravel(y_test))
print(round(basic_LDA_score, 3))


basic_LDA_confMatrix = metrics.confusion_matrix(np.ravel(y_test), basic_LDAModel_pred)
print("Confusion matrix:\n", basic_LDA_confMatrix)

print("")
print("LDA precision:", metrics.precision_score(np.ravel(y_test), basic_LDAModel_pred, average = 'macro'))
print("LDA recall:", metrics.recall_score(np.ravel(y_test), basic_LDAModel_pred, average = 'macro'))
print("LDA kappa:", metrics.cohen_kappa_score(np.ravel(y_test), basic_LDAModel_pred))

#Basic Logistic Regression
basic_logisticModel = LogisticRegression(penalty = 'l2') #l2 because why not
#NOTE: 'l2' and None both got a score of .979
basic_logisticModel.fit(X_train, np.ravel(y_train))
basic_logisticModel_pred = basic_logisticModel.predict(X_test)

basic_logistic_score = basic_logisticModel.score(X_test, np.ravel(y_test))
print(round(basic_logistic_score, 3))

basic_logisticModel_confMatrix = metrics.confusion_matrix(np.ravel(y_test), basic_logisticModel_pred)
print("Confusion matrix:\n", basic_logisticModel_confMatrix)

print("")
print("Logistic Regression precision:", metrics.precision_score(np.ravel(y_test), basic_logisticModel_pred, average = 'macro'))
print("Logistic Regression recall:", metrics.recall_score(np.ravel(y_test), basic_logisticModel_pred, average = 'macro'))
print("Logistic Regression kappa:", metrics.cohen_kappa_score(np.ravel(y_test), basic_logisticModel_pred))

#basic GaussianNB
basic_GNBModel = GaussianNB()
basic_GNBModel.fit(X_train, np.ravel(y_train))
basic_GNB_pred = basic_GNBModel.predict(X_test)

basic_GNBModel_score = basic_GNBModel.score(X_test, np.ravel(y_test))
print(round(basic_GNBModel_score, 3))

basic_GNB_confMatrix = metrics.confusion_matrix(np.ravel(y_test), basic_GNB_pred)
print("Confusion matrix:\n", basic_GNB_confMatrix)

print("")
print("GNB precision:", metrics.precision_score(np.ravel(y_test), basic_GNB_pred, average = 'macro'))
print("GNB recall:", metrics.recall_score(np.ravel(y_test), basic_GNB_pred, average = 'macro'))
print("GNB kappa:", metrics.cohen_kappa_score(np.ravel(y_test), basic_GNB_pred))

#NOTE: LDA BY FAR PERFORMED THE BEST, BY FAR. LIKE, BY 50% BETTER ACCURACY AND MUCH BETTER PRECISION, RECALL, AND KAPPA

#LDA is by far so good I'm not even going to bother gridsearch the others

param_grid = {
    'solver': ['svd', 'lsqr', 'eigen'],
    'priors': [None, [0.3, 0.3, 0.4], [0.2, 0.4, 0.4], [.4, .4, .2], [.4, .2, .4]],
    'n_components': [1, 2],
}

lda = LinearDiscriminantAnalysis()

grid_search = GridSearchCV(estimator=lda, param_grid=param_grid, cv=5, scoring='accuracy')

grid_search.fit(X_train, y_train)


print(f"Best Parameters: {grid_search.best_params_}")
print(f"Best Cross-Validation Score: {grid_search.best_score_}")

# Evaluate on the test set
test_score = grid_search.score(X_test, y_test)
print(f"Test Set Accuracy: {test_score}")

#despite errors, the result is good, fitting a model just for that

best_lda = LinearDiscriminantAnalysis(solver = 'svd', priors = [0.2, 0.4, 0.4], n_components = 1) #even with multiple random runs, these still are best hyperparameters
best_lda.fit(X_train, np.ravel(y_train))

best_lda_pred = best_lda.predict(X_test)

best_lda_score = best_lda.score(X_test, np.ravel(y_test))
print(round(best_lda_score, 3))

best_lda_confMatrix = metrics.confusion_matrix(np.ravel(y_test), best_lda_pred)
print("Confusion matrix:\n", best_lda_confMatrix)

print("")
print("Best LDA precision:", metrics.precision_score(np.ravel(y_test), best_lda_pred, average = 'macro'))
print("Best LDA recall:", metrics.recall_score(np.ravel(y_test), best_lda_pred, average = 'macro'))
print("Best LDA kappa:", metrics.cohen_kappa_score(np.ravel(y_test), best_lda_pred))